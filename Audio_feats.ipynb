{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikitaSUAI/EmotionRecognition/blob/main/Audio_feats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INIT"
      ],
      "metadata": {
        "id": "fdetvFLYTqMr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbyTW-PyLoa2",
        "outputId": "28ff4835-ee5e-439d-b189-61205b734cf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# !cp -r '/content/drive/MyDrive/OMG_EMO' 'OMG_EMO'\n",
        "\n",
        "BASE_PATH = Path(\"/content/drive/MyDrive/OMG_EMO\")\n",
        "\n",
        "TRAIN_PATH = BASE_PATH / \"train_set.csv\"\n",
        "VAL_PATH = BASE_PATH / \"val_set.csv\"\n",
        "TEST_PATH = BASE_PATH / \"test_set.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EgFsLWXTRRRN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_PATH).dropna()\n",
        "val_df = pd.read_csv(VAL_PATH).dropna()\n",
        "test_df = pd.read_csv(TEST_PATH).dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Culc feats"
      ],
      "metadata": {
        "id": "fagqergrTu8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opensmile"
      ],
      "metadata": {
        "id": "f-SrKixJTydL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b27bbf-574a-4f80-e3ad-134869469465"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opensmile\n",
            "  Downloading opensmile-2.4.1-py3-none-any.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 4.1 MB/s \n",
            "\u001b[?25hCollecting audinterface>=0.7.0\n",
            "  Downloading audinterface-0.9.1-py3-none-any.whl (30 kB)\n",
            "Collecting audobject>=0.6.1\n",
            "  Downloading audobject-0.7.5-py3-none-any.whl (24 kB)\n",
            "Collecting audresample<2.0.0,>=1.1.0\n",
            "  Downloading audresample-1.1.0-py3-none-any.whl (635 kB)\n",
            "\u001b[K     |████████████████████████████████| 635 kB 22.7 MB/s \n",
            "\u001b[?25hCollecting audformat<2.0.0,>=0.12.1\n",
            "  Downloading audformat-0.14.3-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas!=1.3.0,!=1.3.1,!=1.3.2,!=1.3.3,!=1.4.0,>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.3.5)\n",
            "Collecting iso-639\n",
            "  Downloading iso-639-0.4.5.tar.gz (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 69.6 MB/s \n",
            "\u001b[?25hCollecting iso3166\n",
            "  Downloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n",
            "Collecting audiofile>=0.4.0\n",
            "  Downloading audiofile-1.1.0-py3-none-any.whl (11 kB)\n",
            "Collecting audeer<2.0.0,>=1.18.0\n",
            "  Downloading audeer-1.18.0-py3-none-any.whl (20 kB)\n",
            "Collecting oyaml\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from audeer<2.0.0,>=1.18.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (4.64.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (from audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (0.10.3.post1)\n",
            "Collecting sox\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from audobject>=0.6.1->opensmile) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas!=1.3.0,!=1.3.1,!=1.3.2,!=1.3.3,!=1.4.0,>=1.1.5->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas!=1.3.0,!=1.3.1,!=1.3.2,!=1.3.3,!=1.4.0,>=1.1.5->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas!=1.3.0,!=1.3.1,!=1.3.2,!=1.3.3,!=1.4.0,>=1.1.5->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile->audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile->audiofile>=0.4.0->audformat<2.0.0,>=0.12.1->audinterface>=0.7.0->opensmile) (2.21)\n",
            "Building wheels for collected packages: iso-639\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=169061 sha256=195a5d881d4506a35a2f6c10c84e0bbe2cdbb0019e6232f86aec92877fab3409\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/60/19/6d020fc92138ed1b113a18271e83ea4b5525fe770cb45b9a2e\n",
            "Successfully built iso-639\n",
            "Installing collected packages: sox, audeer, oyaml, iso3166, iso-639, audiofile, audresample, audformat, audobject, audinterface, opensmile\n",
            "Successfully installed audeer-1.18.0 audformat-0.14.3 audinterface-0.9.1 audiofile-1.1.0 audobject-0.7.5 audresample-1.1.0 iso-639-0.4.5 iso3166-2.1.1 opensmile-2.4.1 oyaml-1.0 sox-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "5Lb4pMvb2kl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdaad200-9a3a-413a-f416-84aa4f19553e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        }
      ],
      "source": [
        "import torchaudio\n",
        "import torch\n",
        "import torchaudio.functional as F\n",
        "import opensmile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "smile = opensmile.Smile(\n",
        "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
        "    feature_level=opensmile.FeatureLevel.Functionals,\n",
        ")\n",
        "\n",
        "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
        "                              model='silero_vad',\n",
        "                              force_reload=True)\n",
        "(get_speech_timestamps,\n",
        " _, read_audio,\n",
        " *_) = utils"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fbanks"
      ],
      "metadata": {
        "id": "AsO9QP6IMiej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fbanks_features(wav_path):\n",
        "  try:\n",
        "    wav_path = BASE_PATH / \"data\" / wav_path\n",
        "    wav, sr = torchaudio.load(wav_path)\n",
        "\n",
        "    re_wav = F.resample(wav[0], sr, 16000)\n",
        "    speech_timestamps = get_speech_timestamps(re_wav, model, sampling_rate=16000)\n",
        "\n",
        "    hop_length = int(10 * 16)\n",
        "    fnank_extractor = torchaudio.transforms.MelSpectrogram(hop_length=hop_length)\n",
        "\n",
        "    fbanks = fnank_extractor(torch.Tensor(re_wav[np.newaxis, :])).numpy()[0]\n",
        "    try:\n",
        "      fbanks_vad = []\n",
        "      for segment in speech_timestamps:\n",
        "        feats = fbanks[:, int(segment['start'] / 160): int(segment['end'] / 160)]               \n",
        "        fbanks_vad.append(feats)\n",
        "      fbanks_vad = np.concatenate(fbanks_vad, axis=1)\n",
        "      return fbanks, fbanks_vad\n",
        "    except :\n",
        "      return fbanks, fbanks\n",
        "  except BaseException:\n",
        "    return None, None \n",
        "a, b = get_fbanks_features(train_df.iloc[0].path)\n",
        "a.shape, b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6Z8clKAA-4j",
        "outputId": "70659dd6-e831-4e9d-a66d-13d6706753ef"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchaudio/functional/functional.py:540: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  \"At least one mel filterbank has all zero values. \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((128, 575), (128, 411))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset = train_df\n",
        "segment_features = subset.path.progress_apply(get_fbanks_features)\n",
        "segment_feats, full_feats = dict(), dict()\n",
        "for (f1, f2), (_, row) in zip(segment_features, subset.iterrows()):\n",
        "  segment_feats[row.path] = f1\n",
        "  full_feats[row.path] = f2\n",
        "\n",
        "with open(\"/content/drive/MyDrive/OMG_EMO/feats/fbanks_segment_train.pkl\", \"wb\") as f:\n",
        "  pickle.dump(segment_feats, f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/OMG_EMO/feats/fbanks_full_train.pkl\", \"wb\") as f:\n",
        "  pickle.dump(full_feats, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVQQ063-V04B",
        "outputId": "5db294c8-b252-44eb-f5bc-0de12f0de045"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1660/1660 [32:34<00:00,  1.18s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset = train_df\n",
        "segment_features = subset.path.progress_apply(get_fbanks_features)\n",
        "\n",
        "segment_feats, full_feats = dict(), dict()\n",
        "for (f1, f2), (_, row) in zip(segment_features, subset.iterrows()):\n",
        "  segment_feats[row.path] = f1\n",
        "  full_feats[row.path] = f2\n",
        "\n",
        "with open(\"/content/drive/MyDrive/OMG_EMO/feats/fbanks_segment_test.pkl\", \"wb\") as f:\n",
        "  pickle.dump(segment_feats, f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/OMG_EMO/feats/fbanks_full_test.pkl\", \"wb\") as f:\n",
        "  pickle.dump(full_feats, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WOm7Z9FXw2v",
        "outputId": "db200877-3d8e-4054-dd4c-543519dad7eb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1660/1660 [05:52<00:00,  4.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenSmile Feats\n",
        "\n",
        "In this section we extract eGeMAPSv02 set from opensmile with and without vad"
      ],
      "metadata": {
        "id": "5foTY0C08jmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_smile_features(wav_path):\n",
        "  try:\n",
        "    wav_path = BASE_PATH / \"data\" / wav_path\n",
        "    wav, sr = torchaudio.load(wav_path)\n",
        "\n",
        "    re_wav = F.resample(wav[0], sr, 16000)\n",
        "    speech_timestamps = get_speech_timestamps(re_wav, model, sampling_rate=16000)\n",
        "\n",
        "    smile_feats_full = smile.process_signal(\n",
        "        wav[0].numpy(),\n",
        "        sr\n",
        "    )\n",
        "    try:\n",
        "      smile_feats_by_vocal_segments = []\n",
        "      for segment in speech_timestamps:\n",
        "        feats = smile.process_signal(\n",
        "            wav[0, int(segment['start'] / 16000 * sr) : int(segment['end'] / 16000 * sr)].numpy(),\n",
        "            sr\n",
        "        )\n",
        "        smile_feats_by_vocal_segments.append(feats)\n",
        "      smile_feats_by_vocal_segments = pd.concat(smile_feats_by_vocal_segments)\n",
        "      return smile_feats_by_vocal_segments, smile_feats_full\n",
        "    except :\n",
        "      return smile_feats_full, smile_feats_full\n",
        "  except BaseException:\n",
        "    return None, None \n",
        "# get_smile_features(train_df.iloc[0].path)"
      ],
      "metadata": {
        "id": "pG1WJyjTXZqF"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wooNPSf83LJA",
        "outputId": "1e0b7b3a-fc7f-4e6d-9ef2-b5ea0c6cc4ac"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7040d78ce522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_text_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msegment_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_smile_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msegment_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0msegment_feats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'video_text_train' is not defined"
          ]
        }
      ],
      "source": [
        "subset = train_df\n",
        "segment_features = subset.path.progress_apply(get_smile_features)\n",
        "segment_feats, full_feats = dict(), dict()\n",
        "for (f1, f2), (_, row) in zip(segment_features, subset.iterrows()):\n",
        "  segment_feats[row.path] = f1\n",
        "  full_feats[row.path] = f2\n",
        "\n",
        "with open(\"/content/drive/MyDrive/OMG_EMO/feats/smile_segment_train.pkl\", \"wb\") as f:\n",
        "  pickle.dump(segment_feats, f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/OMG_EMO/feats/smile_full_train.pkl\", \"wb\") as f:\n",
        "  pickle.dump(full_feats, f)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zef--guxJmjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c66fd6-9553-4b6a-d5c1-84cc8e8e86de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 337/337 [05:24<00:00,  1.04it/s]\n"
          ]
        }
      ],
      "source": [
        "subset = train_df\n",
        "segment_features = subset.path.progress_apply(get_smile_features)\n",
        "\n",
        "segment_feats, full_feats = dict(), dict()\n",
        "for (f1, f2), (_, row) in zip(segment_features, subset.iterrows()):\n",
        "  segment_feats[row.path] = f1\n",
        "  full_feats[row.path] = f2\n",
        "\n",
        "with open(\"/content/drive/MyDrive/OMG_EMO/feats/smile_segment_test.pkl\", \"wb\") as f:\n",
        "  pickle.dump(segment_feats, f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/OMG_EMO/feats/smile_full_test.pkl\", \"wb\") as f:\n",
        "  pickle.dump(full_feats, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXR2vjRC9xyP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRLWuxvawJnc7WkwX12S1H",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}